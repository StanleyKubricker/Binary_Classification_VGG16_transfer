{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57fa11f2-2c11-4f75-b62c-7d3c2a220cf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T13:46:44.182126Z",
     "iopub.status.busy": "2022-11-09T13:46:44.181201Z",
     "iopub.status.idle": "2022-11-09T13:46:46.978988Z",
     "shell.execute_reply": "2022-11-09T13:46:46.978083Z",
     "shell.execute_reply.started": "2022-11-09T13:46:44.182057Z"
    }
   },
   "outputs": [],
   "source": [
    "#Import modules\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications import VGG16\n",
    "from keras import optimizers\n",
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a1115a1-7f9a-4ac7-a75d-1b0781529bd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T13:46:48.528177Z",
     "iopub.status.busy": "2022-11-09T13:46:48.527272Z",
     "iopub.status.idle": "2022-11-09T13:46:48.532187Z",
     "shell.execute_reply": "2022-11-09T13:46:48.531308Z",
     "shell.execute_reply.started": "2022-11-09T13:46:48.528145Z"
    }
   },
   "outputs": [],
   "source": [
    "#Specify path for training, validation and testing data\n",
    "train_dir = '/notebooks/train'\n",
    "test_dir = '/notebooks/test'\n",
    "validation_dir = '/notebooks/validation'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95249a4c-f114-466f-93a0-035b36501a66",
   "metadata": {},
   "source": [
    "### Preprocess and augment images\n",
    "Pre-processing is necessary to convert images to a tensor format that can be fed into model.\n",
    "Data augmentation allows for manipulation of images to artificially increase the size of our training dataset and thus improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f80a791-4b86-4342-9a86-b45c9c6f6abd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T13:46:50.105226Z",
     "iopub.status.busy": "2022-11-09T13:46:50.104439Z",
     "iopub.status.idle": "2022-11-09T13:46:50.198921Z",
     "shell.execute_reply": "2022-11-09T13:46:50.197269Z",
     "shell.execute_reply.started": "2022-11-09T13:46:50.105201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#Instante trainig ImageDataGenerator object\n",
    "#rescale to ensure that all pixel values are in range [0-1]\n",
    "#rotation_range: allow for 40deg. random rotation of images\n",
    "#width_shift_range & height_shift_range: fraction of total width and height that image can be shifted by\n",
    "#shear_range: range in which can shear image\n",
    "#zoom_range: range in which can zoom image\n",
    "#horizontal_flip: allows for horizontal flip of image\n",
    "#fill_mode: areas of image that fall outside of original boundaries are filled as so aaa|abcd|ddd, where | denotes a boundary\n",
    "train_datagenerator = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "\n",
    "#Instantiate testing ImageDataGenerator object\n",
    "#rescale to ensure that all pixel values are in range [0-1]\n",
    "#no further data augmentation\n",
    "test_datagenerator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#Define function to generate augmented training dataset from training data directory\n",
    "def train_prep(data_location, target_image_size):\n",
    "    training_generator = train_datagenerator.flow_from_directory(\n",
    "        data_location,\n",
    "        target_size = target_image_size,\n",
    "        batch_size = 20,\n",
    "        class_mode = 'binary')\n",
    "    return training_generator\n",
    "\n",
    "#Define function to generate validation/testing dataset from data directory\n",
    "def val_test_prep(data_location, target_image_size):\n",
    "    val_test_generator = test_datagenerator.flow_from_directory(\n",
    "        data_location,\n",
    "        target_size = target_image_size,\n",
    "        batch_size = 20,\n",
    "        class_mode = 'binary')\n",
    "    return val_test_generator\n",
    "\n",
    "#Generate training data\n",
    "train_generator = train_prep(train_dir, (150, 150))\n",
    "\n",
    "#Generate validation data\n",
    "validation_generator = val_test_prep(validation_dir, (150, 150))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7b30e0-6bcd-47b8-89e3-12a466578bfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-07T14:29:19.480040Z",
     "iopub.status.busy": "2022-11-07T14:29:19.479761Z",
     "iopub.status.idle": "2022-11-07T14:29:19.487882Z",
     "shell.execute_reply": "2022-11-07T14:29:19.485950Z",
     "shell.execute_reply.started": "2022-11-07T14:29:19.480016Z"
    }
   },
   "source": [
    "### Instantiate pre-trained convolutional base\n",
    "Here we will use VGG16 convolutional base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60ea6b33-392e-4aa6-bf47-af6fae952b14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T13:46:52.996902Z",
     "iopub.status.busy": "2022-11-09T13:46:52.996122Z",
     "iopub.status.idle": "2022-11-09T13:46:54.143036Z",
     "shell.execute_reply": "2022-11-09T13:46:54.142324Z",
     "shell.execute_reply.started": "2022-11-09T13:46:52.996878Z"
    }
   },
   "outputs": [],
   "source": [
    "#Load weights learned from training on image net dataset\n",
    "#Don't include top (will add our own dense classifier)\n",
    "convolutional_base = VGG16(weights = 'imagenet', include_top = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc07711-748d-44bf-baf7-32876e9f5ddf",
   "metadata": {},
   "source": [
    "### Add densely connected layers on top of convolutional base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18ab5dc7-6a7e-4793-adac-491006c8ff70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T13:46:55.469735Z",
     "iopub.status.busy": "2022-11-09T13:46:55.469424Z",
     "iopub.status.idle": "2022-11-09T13:46:55.534236Z",
     "shell.execute_reply": "2022-11-09T13:46:55.533555Z",
     "shell.execute_reply.started": "2022-11-09T13:46:55.469713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, None, None, 512)   14714688  \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,846,273\n",
      "Trainable params: 14,846,273\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Create sequential model\n",
    "my_model = models.Sequential()\n",
    "#Add convolutional base\n",
    "my_model.add(convolutional_base)\n",
    "#Add Global Average Pooling layer to downscale parameter space\n",
    "my_model.add(layers.GlobalAveragePooling2D())\n",
    "#Add dense layers to learn classes and output binary predictions\n",
    "my_model.add(layers.Dense(256, activation = 'relu'))\n",
    "my_model.add(layers.Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "#Display summary of model architecture\n",
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fda3b07-e8b0-442c-8d78-b09f622f092d",
   "metadata": {},
   "source": [
    "### Freeze convolutional base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d4f546b-e66d-433a-9721-a8916bc08bfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T13:46:57.913416Z",
     "iopub.status.busy": "2022-11-09T13:46:57.912786Z",
     "iopub.status.idle": "2022-11-09T13:46:57.917089Z",
     "shell.execute_reply": "2022-11-09T13:46:57.916433Z",
     "shell.execute_reply.started": "2022-11-09T13:46:57.913391Z"
    }
   },
   "outputs": [],
   "source": [
    "convolutional_base.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3088603f-05b8-4506-b326-97a8ca971aae",
   "metadata": {},
   "source": [
    "### Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f6e2a44-72cb-4acf-a32f-29f4ca095679",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T13:46:59.608514Z",
     "iopub.status.busy": "2022-11-09T13:46:59.607931Z",
     "iopub.status.idle": "2022-11-09T13:46:59.619645Z",
     "shell.execute_reply": "2022-11-09T13:46:59.618767Z",
     "shell.execute_reply.started": "2022-11-09T13:46:59.608490Z"
    }
   },
   "outputs": [],
   "source": [
    "my_model.compile(loss = 'binary_crossentropy',\n",
    "                 optimizer = optimizers.RMSprop(learning_rate = 2e-5),\n",
    "                 metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf82f95-288f-495d-bb69-dcb7d711e985",
   "metadata": {},
   "source": [
    "### Train the densely connected layers on training dataset\n",
    "This step is necessary to ensure that the model is making decent predictions before we unfreeze and fine-tune any of the convolutional base.\n",
    "Fine-tuning the convolutional base without first training the densely connected top layers would result in large loss and a very difficult training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80bbb429-4c53-4ff0-bc9b-dc9d2d479db0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T13:47:01.623594Z",
     "iopub.status.busy": "2022-11-09T13:47:01.622925Z",
     "iopub.status.idle": "2022-11-09T13:51:51.300439Z",
     "shell.execute_reply": "2022-11-09T13:51:51.299699Z",
     "shell.execute_reply.started": "2022-11-09T13:47:01.623565Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "100/100 [==============================] - 17s 137ms/step - loss: 0.7404 - acc: 0.4995 - val_loss: 0.6902 - val_acc: 0.5410\n",
      "Epoch 2/30\n",
      "100/100 [==============================] - 9s 90ms/step - loss: 0.6778 - acc: 0.5660 - val_loss: 0.6564 - val_acc: 0.6440\n",
      "Epoch 3/30\n",
      "100/100 [==============================] - 9s 90ms/step - loss: 0.6539 - acc: 0.6520 - val_loss: 0.6290 - val_acc: 0.6830\n",
      "Epoch 4/30\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.6335 - acc: 0.6830 - val_loss: 0.6002 - val_acc: 0.7520\n",
      "Epoch 5/30\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.6077 - acc: 0.7410 - val_loss: 0.5766 - val_acc: 0.7770\n",
      "Epoch 6/30\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.5951 - acc: 0.7390 - val_loss: 0.5569 - val_acc: 0.7840\n",
      "Epoch 7/30\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.5822 - acc: 0.7475 - val_loss: 0.5391 - val_acc: 0.7920\n",
      "Epoch 8/30\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.5693 - acc: 0.7585 - val_loss: 0.5235 - val_acc: 0.7970\n",
      "Epoch 9/30\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.5555 - acc: 0.7715 - val_loss: 0.5084 - val_acc: 0.8100\n",
      "Epoch 10/30\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.5423 - acc: 0.7780 - val_loss: 0.4955 - val_acc: 0.8190\n",
      "Epoch 11/30\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.5299 - acc: 0.7835 - val_loss: 0.4816 - val_acc: 0.8220\n",
      "Epoch 12/30\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.5290 - acc: 0.7780 - val_loss: 0.4696 - val_acc: 0.8310\n",
      "Epoch 13/30\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.5181 - acc: 0.7820 - val_loss: 0.4589 - val_acc: 0.8370\n",
      "Epoch 14/30\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.5126 - acc: 0.7795 - val_loss: 0.4494 - val_acc: 0.8360\n",
      "Epoch 15/30\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.5048 - acc: 0.7845 - val_loss: 0.4413 - val_acc: 0.8480\n",
      "Epoch 16/30\n",
      "100/100 [==============================] - 9s 90ms/step - loss: 0.4967 - acc: 0.7860 - val_loss: 0.4339 - val_acc: 0.8480\n",
      "Epoch 17/30\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.4853 - acc: 0.7985 - val_loss: 0.4243 - val_acc: 0.8480\n",
      "Epoch 18/30\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.4877 - acc: 0.8025 - val_loss: 0.4168 - val_acc: 0.8480\n",
      "Epoch 19/30\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.4772 - acc: 0.8000 - val_loss: 0.4104 - val_acc: 0.8470\n",
      "Epoch 20/30\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.4746 - acc: 0.7960 - val_loss: 0.4045 - val_acc: 0.8510\n",
      "Epoch 21/30\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.4627 - acc: 0.7980 - val_loss: 0.3988 - val_acc: 0.8550\n",
      "Epoch 22/30\n",
      "100/100 [==============================] - 10s 97ms/step - loss: 0.4648 - acc: 0.8000 - val_loss: 0.3931 - val_acc: 0.8560\n",
      "Epoch 23/30\n",
      "100/100 [==============================] - 9s 90ms/step - loss: 0.4605 - acc: 0.8080 - val_loss: 0.3880 - val_acc: 0.8560\n",
      "Epoch 24/30\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.4559 - acc: 0.8120 - val_loss: 0.3830 - val_acc: 0.8570\n",
      "Epoch 25/30\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.4496 - acc: 0.8030 - val_loss: 0.3785 - val_acc: 0.8570\n",
      "Epoch 26/30\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.4459 - acc: 0.8145 - val_loss: 0.3745 - val_acc: 0.8560\n",
      "Epoch 27/30\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.4336 - acc: 0.8195 - val_loss: 0.3715 - val_acc: 0.8710\n",
      "Epoch 28/30\n",
      "100/100 [==============================] - 9s 90ms/step - loss: 0.4359 - acc: 0.8185 - val_loss: 0.3659 - val_acc: 0.8610\n",
      "Epoch 29/30\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.4302 - acc: 0.8210 - val_loss: 0.3620 - val_acc: 0.8620\n",
      "Epoch 30/30\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.4341 - acc: 0.8195 - val_loss: 0.3583 - val_acc: 0.8610\n"
     ]
    }
   ],
   "source": [
    "history_dense_top = my_model.fit(\n",
    "      train_generator,\n",
    "      steps_per_epoch=100,\n",
    "      epochs=30,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e7f0ac0-73ca-4ea4-a534-9bcddbb340f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T13:53:18.784998Z",
     "iopub.status.busy": "2022-11-09T13:53:18.784695Z",
     "iopub.status.idle": "2022-11-09T13:53:21.259515Z",
     "shell.execute_reply": "2022-11-09T13:53:21.258845Z",
     "shell.execute_reply.started": "2022-11-09T13:53:18.784975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 730 images belonging to 2 classes.\n",
      "37/37 [==============================] - 2s 64ms/step - loss: 0.3630 - acc: 0.8562\n",
      "test acc: 0.8561643958091736\n"
     ]
    }
   ],
   "source": [
    "#Evaluate model before fine tuning\n",
    "test_generator = test_datagenerator.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "test_loss_, test_acc_ = my_model.evaluate(test_generator, steps=37)\n",
    "print('test acc:', test_acc_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155c199b-edc1-4a6a-bbb5-10d94929575f",
   "metadata": {},
   "source": [
    "Without fine-tuning the convolutional base, the model achieves 84.5% accuracy on the validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323360db-40d8-4571-afe1-686929799d7c",
   "metadata": {},
   "source": [
    "### Unfreeze final 3 layers of convolutional base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3e6e155-aea0-4416-9b27-7f4b8c45f54e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T13:53:24.029648Z",
     "iopub.status.busy": "2022-11-09T13:53:24.029333Z",
     "iopub.status.idle": "2022-11-09T13:53:24.051126Z",
     "shell.execute_reply": "2022-11-09T13:53:24.050508Z",
     "shell.execute_reply.started": "2022-11-09T13:53:24.029626Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None, None, 3)]   0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, None, None, 64)    1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, None, None, 64)    36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, None, None, 64)    0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, None, None, 128)   73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, None, None, 128)   147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, None, None, 128)   0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, None, None, 256)   295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, None, None, 256)   590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, None, None, 256)   0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, None, None, 512)   1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, None, None, 512)   2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, None, None, 512)   0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Display structure of convolutional base\n",
    "convolutional_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c31ac7-2901-439d-89c5-0bdf00315ea3",
   "metadata": {},
   "source": [
    "Therefore everything before block5 should remain frozen, and block5 will be unfrozen ready for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9cb7969-5f01-4d6f-a0dd-daf74267cfd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T13:53:26.273156Z",
     "iopub.status.busy": "2022-11-09T13:53:26.272886Z",
     "iopub.status.idle": "2022-11-09T13:53:26.277633Z",
     "shell.execute_reply": "2022-11-09T13:53:26.276839Z",
     "shell.execute_reply.started": "2022-11-09T13:53:26.273136Z"
    }
   },
   "outputs": [],
   "source": [
    "#Unfreeze all convolutional layers in block5\n",
    "convolutional_base.trainable = True\n",
    "\n",
    "for layer in convolutional_base.layers:\n",
    "    if layer.name in ['block5_conv1', 'block5_conv2', 'block5_conv3']:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cd9824e-0ab3-490f-bd51-06eb7e76a1c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T13:53:29.072022Z",
     "iopub.status.busy": "2022-11-09T13:53:29.071690Z",
     "iopub.status.idle": "2022-11-09T13:53:29.079262Z",
     "shell.execute_reply": "2022-11-09T13:53:29.078515Z",
     "shell.execute_reply.started": "2022-11-09T13:53:29.072000Z"
    }
   },
   "outputs": [],
   "source": [
    "#Compile model\n",
    "my_model.compile(loss = 'binary_crossentropy',\n",
    "                 optimizer = optimizers.RMSprop(learning_rate = 1e-5),\n",
    "                 metrics = ['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2b6c00-40d2-496a-8ad5-289adb58ec0f",
   "metadata": {},
   "source": [
    "### Finetune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7d45445-7aad-4956-a021-8e2e560bff6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T13:53:30.190079Z",
     "iopub.status.busy": "2022-11-09T13:53:30.189274Z",
     "iopub.status.idle": "2022-11-09T14:09:09.322042Z",
     "shell.execute_reply": "2022-11-09T14:09:09.321456Z",
     "shell.execute_reply.started": "2022-11-09T13:53:30.190045Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "100/100 [==============================] - 10s 94ms/step - loss: 0.3761 - acc: 0.8365 - val_loss: 0.2556 - val_acc: 0.8850\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.3068 - acc: 0.8670 - val_loss: 0.2151 - val_acc: 0.9050\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.2655 - acc: 0.8945 - val_loss: 0.2059 - val_acc: 0.9040\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.2565 - acc: 0.8955 - val_loss: 0.1956 - val_acc: 0.9100\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.2331 - acc: 0.9005 - val_loss: 0.1762 - val_acc: 0.9300\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.2155 - acc: 0.9050 - val_loss: 0.1739 - val_acc: 0.9280\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.2019 - acc: 0.9175 - val_loss: 0.1746 - val_acc: 0.9180\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.2110 - acc: 0.9075 - val_loss: 0.1721 - val_acc: 0.9220\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.1839 - acc: 0.9265 - val_loss: 0.1946 - val_acc: 0.9140\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.1808 - acc: 0.9255 - val_loss: 0.1612 - val_acc: 0.9270\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.1726 - acc: 0.9300 - val_loss: 0.2062 - val_acc: 0.9220\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.1528 - acc: 0.9395 - val_loss: 0.1648 - val_acc: 0.9310\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.1586 - acc: 0.9320 - val_loss: 0.1943 - val_acc: 0.9270\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.1467 - acc: 0.9375 - val_loss: 0.2535 - val_acc: 0.9040\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.1390 - acc: 0.9405 - val_loss: 0.1718 - val_acc: 0.9300\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.1463 - acc: 0.9405 - val_loss: 0.1668 - val_acc: 0.9380\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.1300 - acc: 0.9470 - val_loss: 0.1675 - val_acc: 0.9280\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.1341 - acc: 0.9450 - val_loss: 0.1794 - val_acc: 0.9360\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.1292 - acc: 0.9495 - val_loss: 0.1856 - val_acc: 0.9280\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.1197 - acc: 0.9500 - val_loss: 0.1803 - val_acc: 0.9240\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.1202 - acc: 0.9515 - val_loss: 0.1675 - val_acc: 0.9310\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.1167 - acc: 0.9560 - val_loss: 0.1925 - val_acc: 0.9270\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.1078 - acc: 0.9590 - val_loss: 0.1574 - val_acc: 0.9350\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.1016 - acc: 0.9615 - val_loss: 0.1590 - val_acc: 0.9340\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.1011 - acc: 0.9605 - val_loss: 0.1477 - val_acc: 0.9370\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0996 - acc: 0.9620 - val_loss: 0.1489 - val_acc: 0.9380\n",
      "Epoch 27/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.1015 - acc: 0.9620 - val_loss: 0.3090 - val_acc: 0.9040\n",
      "Epoch 28/100\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.0840 - acc: 0.9700 - val_loss: 0.1744 - val_acc: 0.9270\n",
      "Epoch 29/100\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0888 - acc: 0.9660 - val_loss: 0.1569 - val_acc: 0.9380\n",
      "Epoch 30/100\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.0928 - acc: 0.9655 - val_loss: 0.1646 - val_acc: 0.9350\n",
      "Epoch 31/100\n",
      "100/100 [==============================] - 10s 95ms/step - loss: 0.0748 - acc: 0.9720 - val_loss: 0.1832 - val_acc: 0.9340\n",
      "Epoch 32/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0907 - acc: 0.9650 - val_loss: 0.1831 - val_acc: 0.9260\n",
      "Epoch 33/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0819 - acc: 0.9690 - val_loss: 0.1623 - val_acc: 0.9400\n",
      "Epoch 34/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0854 - acc: 0.9660 - val_loss: 0.1391 - val_acc: 0.9390\n",
      "Epoch 35/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0835 - acc: 0.9660 - val_loss: 0.1670 - val_acc: 0.9350\n",
      "Epoch 36/100\n",
      "100/100 [==============================] - 9s 90ms/step - loss: 0.0760 - acc: 0.9705 - val_loss: 0.1618 - val_acc: 0.9400\n",
      "Epoch 37/100\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.0767 - acc: 0.9730 - val_loss: 0.2130 - val_acc: 0.9220\n",
      "Epoch 38/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0757 - acc: 0.9740 - val_loss: 0.1781 - val_acc: 0.9360\n",
      "Epoch 39/100\n",
      "100/100 [==============================] - 9s 90ms/step - loss: 0.0620 - acc: 0.9790 - val_loss: 0.1492 - val_acc: 0.9430\n",
      "Epoch 40/100\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.0599 - acc: 0.9790 - val_loss: 0.2060 - val_acc: 0.9310\n",
      "Epoch 41/100\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0571 - acc: 0.9790 - val_loss: 0.2342 - val_acc: 0.9260\n",
      "Epoch 42/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0601 - acc: 0.9775 - val_loss: 0.1763 - val_acc: 0.9380\n",
      "Epoch 43/100\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.0719 - acc: 0.9780 - val_loss: 0.2161 - val_acc: 0.9270\n",
      "Epoch 44/100\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.0654 - acc: 0.9760 - val_loss: 0.1902 - val_acc: 0.9290\n",
      "Epoch 45/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0672 - acc: 0.9760 - val_loss: 0.1743 - val_acc: 0.9320\n",
      "Epoch 46/100\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.0644 - acc: 0.9805 - val_loss: 0.1618 - val_acc: 0.9390\n",
      "Epoch 47/100\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.0438 - acc: 0.9875 - val_loss: 0.1762 - val_acc: 0.9420\n",
      "Epoch 48/100\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0565 - acc: 0.9805 - val_loss: 0.2972 - val_acc: 0.9180\n",
      "Epoch 49/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0494 - acc: 0.9840 - val_loss: 0.1451 - val_acc: 0.9420\n",
      "Epoch 50/100\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0414 - acc: 0.9845 - val_loss: 0.1732 - val_acc: 0.9420\n",
      "Epoch 51/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0519 - acc: 0.9830 - val_loss: 0.2227 - val_acc: 0.9340\n",
      "Epoch 52/100\n",
      "100/100 [==============================] - 9s 90ms/step - loss: 0.0494 - acc: 0.9805 - val_loss: 0.1740 - val_acc: 0.9390\n",
      "Epoch 53/100\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0596 - acc: 0.9765 - val_loss: 0.1847 - val_acc: 0.9370\n",
      "Epoch 54/100\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.0438 - acc: 0.9865 - val_loss: 0.1833 - val_acc: 0.9390\n",
      "Epoch 55/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0435 - acc: 0.9835 - val_loss: 0.2707 - val_acc: 0.9230\n",
      "Epoch 56/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0406 - acc: 0.9870 - val_loss: 0.2306 - val_acc: 0.9300\n",
      "Epoch 57/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0408 - acc: 0.9840 - val_loss: 0.1578 - val_acc: 0.9390\n",
      "Epoch 58/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0467 - acc: 0.9800 - val_loss: 0.1833 - val_acc: 0.9330\n",
      "Epoch 59/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0368 - acc: 0.9850 - val_loss: 0.1900 - val_acc: 0.9430\n",
      "Epoch 60/100\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.0389 - acc: 0.9875 - val_loss: 0.1756 - val_acc: 0.9430\n",
      "Epoch 61/100\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0443 - acc: 0.9835 - val_loss: 0.1728 - val_acc: 0.9410\n",
      "Epoch 62/100\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.0405 - acc: 0.9840 - val_loss: 0.2406 - val_acc: 0.9290\n",
      "Epoch 63/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0382 - acc: 0.9865 - val_loss: 0.1809 - val_acc: 0.9420\n",
      "Epoch 64/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0348 - acc: 0.9860 - val_loss: 0.2123 - val_acc: 0.9390\n",
      "Epoch 65/100\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0350 - acc: 0.9870 - val_loss: 0.1948 - val_acc: 0.9410\n",
      "Epoch 66/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0526 - acc: 0.9785 - val_loss: 0.2218 - val_acc: 0.9330\n",
      "Epoch 67/100\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.0301 - acc: 0.9895 - val_loss: 0.1942 - val_acc: 0.9380\n",
      "Epoch 68/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0342 - acc: 0.9895 - val_loss: 0.1843 - val_acc: 0.9420\n",
      "Epoch 69/100\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.0374 - acc: 0.9850 - val_loss: 0.1922 - val_acc: 0.9400\n",
      "Epoch 70/100\n",
      "100/100 [==============================] - 9s 90ms/step - loss: 0.0271 - acc: 0.9905 - val_loss: 0.2645 - val_acc: 0.9240\n",
      "Epoch 71/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0452 - acc: 0.9860 - val_loss: 0.3119 - val_acc: 0.9110\n",
      "Epoch 72/100\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0407 - acc: 0.9875 - val_loss: 0.1704 - val_acc: 0.9400\n",
      "Epoch 73/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0287 - acc: 0.9900 - val_loss: 0.2284 - val_acc: 0.9290\n",
      "Epoch 74/100\n",
      "100/100 [==============================] - 11s 106ms/step - loss: 0.0339 - acc: 0.9880 - val_loss: 0.1982 - val_acc: 0.9390\n",
      "Epoch 75/100\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0329 - acc: 0.9870 - val_loss: 0.1993 - val_acc: 0.9400\n",
      "Epoch 76/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0288 - acc: 0.9900 - val_loss: 0.2805 - val_acc: 0.9290\n",
      "Epoch 77/100\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.0334 - acc: 0.9890 - val_loss: 0.2554 - val_acc: 0.9320\n",
      "Epoch 78/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0260 - acc: 0.9915 - val_loss: 0.1990 - val_acc: 0.9420\n",
      "Epoch 79/100\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.0300 - acc: 0.9895 - val_loss: 0.1955 - val_acc: 0.9380\n",
      "Epoch 80/100\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0310 - acc: 0.9905 - val_loss: 0.2633 - val_acc: 0.9310\n",
      "Epoch 81/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0217 - acc: 0.9935 - val_loss: 0.2132 - val_acc: 0.9410\n",
      "Epoch 82/100\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.0364 - acc: 0.9880 - val_loss: 0.2319 - val_acc: 0.9380\n",
      "Epoch 83/100\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.0199 - acc: 0.9955 - val_loss: 0.2470 - val_acc: 0.9350\n",
      "Epoch 84/100\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0281 - acc: 0.9920 - val_loss: 0.2006 - val_acc: 0.9440\n",
      "Epoch 85/100\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.0351 - acc: 0.9870 - val_loss: 0.2146 - val_acc: 0.9410\n",
      "Epoch 86/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0347 - acc: 0.9860 - val_loss: 0.1868 - val_acc: 0.9430\n",
      "Epoch 87/100\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.0287 - acc: 0.9905 - val_loss: 0.1770 - val_acc: 0.9420\n",
      "Epoch 88/100\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0308 - acc: 0.9920 - val_loss: 0.3567 - val_acc: 0.9130\n",
      "Epoch 89/100\n",
      "100/100 [==============================] - 9s 94ms/step - loss: 0.0224 - acc: 0.9925 - val_loss: 0.3118 - val_acc: 0.9240\n",
      "Epoch 90/100\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0351 - acc: 0.9915 - val_loss: 0.2529 - val_acc: 0.9320\n",
      "Epoch 91/100\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.0344 - acc: 0.9885 - val_loss: 0.2505 - val_acc: 0.9290\n",
      "Epoch 92/100\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.0257 - acc: 0.9910 - val_loss: 0.2041 - val_acc: 0.9410\n",
      "Epoch 93/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0298 - acc: 0.9895 - val_loss: 0.1921 - val_acc: 0.9460\n",
      "Epoch 94/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0247 - acc: 0.9905 - val_loss: 0.3211 - val_acc: 0.9280\n",
      "Epoch 95/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0229 - acc: 0.9925 - val_loss: 0.2517 - val_acc: 0.9350\n",
      "Epoch 96/100\n",
      "100/100 [==============================] - 9s 92ms/step - loss: 0.0258 - acc: 0.9915 - val_loss: 0.2476 - val_acc: 0.9380\n",
      "Epoch 97/100\n",
      "100/100 [==============================] - 9s 91ms/step - loss: 0.0208 - acc: 0.9945 - val_loss: 0.2725 - val_acc: 0.9290\n",
      "Epoch 98/100\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0248 - acc: 0.9910 - val_loss: 0.2858 - val_acc: 0.9310\n",
      "Epoch 99/100\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0286 - acc: 0.9910 - val_loss: 0.2271 - val_acc: 0.9380\n",
      "Epoch 100/100\n",
      "100/100 [==============================] - 9s 93ms/step - loss: 0.0342 - acc: 0.9890 - val_loss: 0.1984 - val_acc: 0.9410\n"
     ]
    }
   ],
   "source": [
    "history_final = my_model.fit(\n",
    "              train_generator,\n",
    "              steps_per_epoch=100,\n",
    "              epochs=100,\n",
    "              validation_data=validation_generator,\n",
    "              validation_steps=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06718bb-b527-43e3-8924-cf24fc34ab2b",
   "metadata": {},
   "source": [
    "### Evaluate performance of fine-tuned model on testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d7bce5c-c565-4baa-823a-300a1ff9c5ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-11-09T14:19:31.002337Z",
     "iopub.status.busy": "2022-11-09T14:19:31.001754Z",
     "iopub.status.idle": "2022-11-09T14:19:32.345010Z",
     "shell.execute_reply": "2022-11-09T14:19:32.344263Z",
     "shell.execute_reply.started": "2022-11-09T14:19:31.002310Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 730 images belonging to 2 classes.\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.3138 - acc: 0.9329\n",
      "test acc: 0.932876706123352\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagenerator.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(150, 150),\n",
    "        batch_size=20,\n",
    "        class_mode='binary')\n",
    "test_loss, test_acc = my_model.evaluate(test_generator, steps=37)\n",
    "print('test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5be75c-026d-4702-b725-a4ee78e27686",
   "metadata": {},
   "source": [
    "After fine-tuning the convolutional base, the model achieves 93.3% accuracy on the validation set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
